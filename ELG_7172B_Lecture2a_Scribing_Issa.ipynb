{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELG_7172B_Lecture2a_Scribing_Issa.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rajshekharM/Lecture-scribing/blob/master/ELG_7172B_Lecture2a_Scribing_Issa.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "AvrW0fVp1VS3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lecture 2 Notes - Part 1"
      ]
    },
    {
      "metadata": {
        "id": "cTFxYdQ31VS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Probability Definition\n",
        "There are two different kinds of probability. The first is related to the number of times an event occur. We refer to this as **frequentist probability**. The other kind of probability is related to the _degree of belief_ is called **Bayesian probability** [1].<br>\n",
        "An example on the former could be: after tossing a die for 1000 times, we will realize that the probability of each of the numbers appearing is 1/6. \n",
        "An example on Bayesian probability could be: Given that it is cloudy, I am 50% sure that it is going to rain. After successive events, i.e., after observing what happens after its cloudy, I might be 80% sure that it is going to rain. "
      ]
    },
    {
      "metadata": {
        "id": "ABD0MIUQ1VS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Variables\n",
        "\n",
        "A random variable is a variable that can take on different values randomly. We refer to the random variable by $X$, and the values that it can be assigned as $x_1, x_2$... \n",
        "\n",
        "$\\Omega$: This is the sample space.<br>\n",
        "$A$: reflects the outcomes that we observed<br>\n",
        "$P$: Probability measures\n",
        "\n",
        "Therefore, the Random Variable will be the mapping from the sample space $\\Omega$ to a real number $R$. Note that $\\Omega$ could be not only numbers, but states. Therefore, when referring to a die, $\\Omega$ could be the states *odd* and *even*.\n",
        "\n",
        "So if we are tossing a die => we have a random process. \n",
        "$\\Omega$: = {1, 2, 3, 4, 5, 6} <br>\n",
        "And the probability $P$ of each outcome will be $\\frac{1}{6}$.\n",
        "\n",
        "We can say: $P(X\\, is\\, even)\\, =\\, P(X\\, is\\, odd) = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}$"
      ]
    },
    {
      "metadata": {
        "id": "J9d3gwSz1VS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some properties\n",
        "\n",
        "### *Joint Probability Distribution*<br>\n",
        "A probability mass function (Discrete distribution) or probability density function(continuous distribution) can operate on many random variables at the same time. Such probability is called **joint probability distribution**. We refer to it as: $P(X = x, Y = y)$ which mean the probability of having $X = x$ and $Y = y$. For brevity, we can say $P(x, y)$ [1]. <br>\n",
        "If we consider 2 discrete random varaibles $X$ and $Y$, the sum of all the entries of the joint probability table should sum to 1. For example [2]:\n",
        "\n",
        "<img src=\"joint_prob_table_ex.PNG\">\n",
        "\n",
        "Then, the content of this table reflects the following facts: $P(x\\ =\\ 0\\ \\cap\\ y\\ =\\ 0)\\ =\\ 0.1$. Each combinaiton of the values for $X$ and $Y$ is an outcome that can occur with certain probability. Also, we can say: what is the probability that $X\\ \\leq\\ 1$ and $Y\\ \\leq\\ 1$, and this will consist of the outcomes in which $(X,\\ Y)$ is $(0,\\ 0),\\ (0,\\ 1),\\ (1,\\ 0),\\ and\\ (1,\\ 1)$. Then, the probability of this event is equal to $0.10 + 0.04 + 0.08 + 0.20 = 0.42$. <br>\n",
        "Note that the events need not correspond to rectangluar regions in the table. For instance, the event $X\\ <\\ Y$ correspond to $(X,\\ Y)$ combinaitons of $(0,1),(0,2),\\ and\\ (1,2)$. So $P(x\\ <\\ Y)\\ =\\ 0.04\\ +\\ 0.02\\ +\\ 0.06\\ =\\ 0.12$ [2].\n",
        "\n",
        "### *Marginal Probability Distribution*<br>\n",
        "Marginal probability distribution is the attempt to find the probability distribution over a subset of variables when the joint probability distribution over all the variables is known. For example, if we know $P(x, y)$, then to find $P(x)$, we can apply the **sum rule** as [2]: $P(X = x_i) = \\sum_{j} P(X = x_i, Y = y_j)$\n",
        "\n",
        "When working with continous random variable, we should use integration rather than summation: $P(x) = \\int_y P(x, y)dy$.\n",
        "\n",
        "If we consider the above example, we can find the $P(X\\ =\\ x)$ regardless of the value of $Y$. Hence, $P(X\\ =\\ 1)=0.08 + 0.2 + 0.06=0.34$. But of course $P(X\\ =\\ x)$ is just the probability mass function for $X$ alone, when we obtain it from the joint pmf, we can call it a marginal pmf [2]. Ex: <br>\n",
        "$p_X(x)=P(X=x)= \\sum_y p(x,y)$ and likewise, $p_Y(y)=P(Y=y)=\\sum_x p(x,y)$. Therefore, for the example above, we can sum the columns to get the marginal pmf $p_Y(y):$ <img src=\"marginal_pmf_y.PNG\">\n",
        "\n",
        "or sum the rows to get the marginal pmf $p_X(x)$:<img src=\"marginal_pmf_x.PNG\">\n",
        "\n",
        "They're called marginal pmfs because you can write the sum of columns and rows in the margins as:\n",
        "\n",
        "<img src=\"marginal_pmf_xy.PNG\">\n",
        "\n",
        "\n",
        "### *Conditional Probability Distribution*<br>\n",
        "Sometimes, we are interested in the probability of some event, given that other event has happened. so the probability of having $Y = y$ given that $X = x$ is: $P(Y = y\\ /\\ X = x) = \\frac{P(Y = y,\\ X = x)}{P(X = x)}$. [2]\n",
        "\n",
        "Now note that if we consider the case of two continuous random variables, we can extend the definition of the pdf by considering the probability that $X$ and $Y$ lie in a tiny box centered on $(x,y)$ with sides $\\Delta x$ and $\\Delta y$. this probability will go to zero as either $\\Delta x$ or $\\Delta y$ goes to zero, but if we divide by $\\Delta x \\Delta y$ we will get something which remains finite. This is the joint *pdf*. So in this case we will use Integration instead of the summation [2]:\n",
        "\n",
        "$P((a\\ <\\ X\\ <\\ b) \\cap (c\\ <\\ Y\\ <\\ d)) = \\int_a^b (\\int_c^d f(x,y)dy)dx = \\int_c^d (\\int_a^b f(x,y)dx)dy$.\n",
        "\n",
        "Finally: $\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)dxdy=1$.\n",
        "\n",
        "Now suppose we want to find the conditional probability distribution. Let's take: $P(X=1 | Y=0) = 0.08/0.24=0.333$, likewise, we can compute $P(Y = 2 | X = 1) = 0.02/0.16=0.125$\n",
        "\n",
        "### *Chain Rule of Conditional Probabilities*<br>\n",
        "The joint probability over many random variables can be decomposed into conditional distribution over only one variable [1]:\n",
        "\n",
        "$P(X_1, X_2, X_3, \\cdots, X_n) = P(X_1) \\prod_{i=2}^{n} P(X_i | X_1, \\cdots, X_i)$\n",
        "    \n",
        "Ex: $$ P(a,\\ b,\\ c) = P(a\\ |\\ b,\\ c)\\ P(b,\\ c) \\\\ P(b,\\ c) = P(b\\ |\\ c)\\ P(c) \\\\ P(a,\\ b,\\ c) = P(a\\ |\\ b,\\ c)\\ P(b\\ |\\ c)\\ P(c)$$\n",
        "\n",
        "### *Expextation, Variance and Covariance*<br>\n",
        "Given a certain space event $\\Omega$ that contains some events ${w_1, w_2, \\cdots, w_n}$ where each event occur with a probability ${p_1, p_2, \\cdots, p_n}$. Therefore, the average of the events that could take place is: $p_1 w_1 + p_2 w_2 + \\cdots + p_n w_n$. If the events are grades, taking some discrete values, then the expectation $E$ will be the average of the grades. In general, the expected value of some random variable $X$ with respect to the some probability distribution $P(X)$ is designed as follows: $E_{x \\sim P}[X] = \\sum_x P(x)\\ X$, while for a continuous random variable, that becomes: $E_{x \\sim P}[X] = \\int_x P(x)\\ Xdx$, where $\\sim$ means that x is sampled from some probability distribution $P$ [1].\n",
        "\n",
        "Expectations are linear. Ex:\n",
        "\n",
        "$E_x[\\alpha f(x) + \\beta g(x)] = \\alpha E_x[f(x)] + \\beta E_x[g(x)]$ as long as $\\alpha$ and $\\beta$ are independent of x.\n",
        "\n",
        "The **variance** gives a measure of how much the values of a function of random variable x vary as we sample different values from x from its probability distribution:\n",
        "\n",
        "$Var(X) = E[(X\\ -\\ \\mu_x)^2]$\n",
        "\n",
        "When the variance is low, the values of $X$ cluster near the expected value. \n",
        "\n",
        "The square root of the variance is known as the standard deviation: $\\sigma_x = \\surd Var(X)$. The standard deviation represents how much the data is far away from the mean $\\mu_x$\n",
        "\n",
        "Covariance is the *linear* relationship between $X$ and $Y$.\n",
        "\n",
        "$Cov(X, Y) = E\\ [(X - \\mu_x)\\ (Y - \\mu_y)]\\ =\\ E(XY)\\ -\\ \\mu_x \\mu_y$\n",
        "\n",
        "The covariance will be translated into a matrix where the diagonal is representing the variance. \n",
        "\n",
        "$X = \\begin{bmatrix}x_1\\\\x_2\\\\x_3\\\\\\vdots\\\\x_n\\end{bmatrix}$ => $Cov(X) = \\begin{bmatrix}\n",
        "cov(x_1, x_1)&cov(x_1, x_2)&\\cdots &cov(x_1, x_n) \\\\\n",
        "cov(x_2, x_1)&cov(x_2, x_2)&\\cdots &cov(x_2, x_n) \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "cov(x_n, x_1)&cov(x_n, x_2)&\\cdots &cov(x_n, x_n)\n",
        "\\end{bmatrix}$\n",
        "\n",
        "### *Bayes Theorem*\n",
        "$P(x,\\ y)\\ =\\ P(y|x)\\ P(x)\\ =\\ P(x|y)\\ P(y)\\\\ \\Rightarrow\\ P(\\theta|D)\\ =\\ \\frac{P(D|\\theta)\\ P(\\theta)}{P(D)}$ <br>\n",
        "Where: <br>\n",
        "$P(\\theta|D)$ is our posterior. <br>\n",
        "$P(D|\\theta)$ is our likelihood. <br>\n",
        "$P(\\theta)$ is our prior. <br>\n",
        "$P(D)$ is our marginal probability. <br>\n",
        "\n",
        "## The Workflow of Uncertainty Qualification\n",
        "\n",
        "The work flow is divided into 4 main steps as shown in the figure below. \n",
        "\n",
        "<img src=\"Workflow_of_Uncertainty_Quantification.png\">\n",
        "Workflow of Uncertainty Quantification based on OpenTurns [9]\n",
        "\n",
        "**Step A**: There is a need to define the problem in hand. So we might say for example, given that we have some information about the number of rooms for some houses and their prices, we need to develop a model that is capable of creating a mapping from $x$, the number of rooms, to $y$, the price of the home. Hence, our model will become: $y = ax$. On the other hand, we might get some information that our current data is not accurate enough. Therefore, our new model would become: $y = ax + \\epsilon$ [5]. Another model could be: $y = ax^3 + bx^2 + cx + d$. <br>\n",
        "Here there is a need to determine the variable of interest on which the uncertainty has to be quantified. Therefore, in the previous example, our variable of interest will be the house price, or variable $y$. But, what if the inputs are not deterministic, in other words, our input is stochastic, such as with the weather, (so $x$ could describe the certainty for snowing this year in Ottawa, and we need to find the probability of having more snow next year). Hence, the input become stochastic as well. Or lets say that an industry is willing to build a dyke next to a river to protect the industry from floods. Therefore, $x$, which is our input will incur some uncertainty. So there is a need to avoid over or under-dimensioning of the hight as to avoid the risk and save money [3]. <br>\n",
        "Notice that sometimes, the model will output our variable of interest, say $y$, plus another variable that is used by the same model in the next time step. So these kind of models could be best suited to model sequences of data, where the next output is dependent on not only the next input, but on the current input as well [3].<br>\n",
        "Therefore, after step A, we will determine determine and stochastic parmaters in the inputs, the model mathematical function, the variable of interest $Y$, and some of its properties like dispersion, its distribution, probability to exceed a threshold and so on [3]... \n",
        "\n",
        "**Step B**: At this step, the main goal to determine the probability distribution over the set of input variables. So suppose that the problem is some disease diagnostic, or, an image (each pixel will correspond to one variable) and we are required to label the image. So, figuring out the probability distribution of the input will be useful in labeling new images. In other words, if we knew the probability distribution for some cat images, we will be able to categories a new unseen image (I mean, a model who is not trained on that particular image). In other words, if the values of pixels of the new unseen image, and the relationship between some pixels look like some of the examples we have in hand, we can say that the new image is a cat. Remember that the all cats have lots of similar texture which enabled human to guess even though the cat is ocluded [6][7]. \n",
        "Furthermore, some variables might not uncorrelated or independent. In this case, it will be enough to find the probability distribution of each variable alone.<br>\n",
        "Finding the probability distribution of the input might be so hard as with the case of images, where the input is composed of thousands of dimensions (we might have a 16M pixel image). Also, a disease could be determined with thousands of variables, so, determining the independent variable might require the knowledge of some expertise [6][7].  \n",
        "\n",
        "In **Step B'**: we do model calibration so that the output of the model as similar to the observed data. In other words, we will be tweeking the parameters in order to get outputs which are as close as possible to \"labels\" or observed data. We denote this process as tunning the model. The 2 methods involved in this case are maximum likelihood and Bayesian methods for parameter estimation. The former is used to better predict future data. The later method will account for uncertainty in the predictions [8]. \n",
        "\n",
        "**Step C**: This is done to know how good our model is. This is divided into 2 sub steps. *Sensitivity analysis* and *Uncertainty propagation* [8]. <br>\n",
        "In *Uncertainty Propagation*: the aim is to quantify output uncertainties. It allows us to place confidence on the model predictions. Also, we combine all the uncertainties and then see what components in your system need to be replaced and or improved. The aim is to meet the design specification of your device [8].\n",
        "With *sensitivity analysis*, we have to take care of several factors. First, we study the effect of the each input on the output. Hence, this is done through the derivative of the output with respect to the input which keeping all other variables fixed. But, if the model is non linear and various input parameters are affected by uncertainties of different order of magnitude, this factor \"local sensitivity\" should not be used. Hence, there is a need to perform global sensitivity which studies the effect of $x_i$ to the output while all other input factors $x_j$ are varied as well. In this case, we consider Monte Carlo simulation for Parameter space exploration. Hence, after analysing the relationship between the input and the output of the model, it will become possible to relate the variability of the output to the variability of the input. Also, at this stage, we will use simulated data instead of real one. Finally, this will help identifying the most important paramters in the model and fix the unimportant ones to simplify our model. Last but not the least, the variability of the output is measured through its variance[8]. \n",
        "\n",
        "Monte Carlo Definition: we sample one point from each of the input distributions, propagate through the output and get one point at the output. Then take another point randomly, and propagate through the output. Then do this 10,000 times, maybe more. Then we plot a histogram and find the probability of the output. \n",
        "\n",
        "**Step D**: Non-parameteric methods for time series, e.g., Bootstrap for time series. Parametric methods: Kalman filters for linear and Gaussian models. Practicle filters: these are able to represent arbitrary densities, are capable of focusing on probable regions of state-space, are able to deal with random noise and the framework will allow the inclusion of multiple models[8]."
      ]
    },
    {
      "metadata": {
        "id": "hP2P_YO51VS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "[1] Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. Retrieved from http://www.deeplearningbook.org\n",
        "\n",
        "[2] Joint Probability Distributions and Random Samples. (2010). In Probability and Statistics for Engineers. Retrieved from http://ccrg.rit.edu/~whelan/courses/2010_4wi_1016_345 \n",
        "\n",
        "[3] Baudin, Michaël & Lebrun, Régis & Iooss, Bertrand & Popelin, Anne-Laure. (2015). OpenTURNS: An Industrial Software for Uncertainty Quantification in Simulation. 1-38. 10.1007/978-3-319-11259-6_64-1. \n",
        "\n",
        "[4] Reference Guide - OpenTURNS. (n.d.). Retrieved January 21, 2018, from http://www.bing.com/cr?IG=9CAFE0E1DA9B4AC09EA19F9F40635F24&CID=2295C1BA17F6696B2E91CAC416596836&rd=1&h=oiHO_mW5i9p-srb9qw2jUlyZmwyekAnI2rTry-vJma4&v=1&r=http%3a%2f%2fdoc.openturns.org%2fopenturns-latest%2fpdf%2fOpenTURNS_ReferenceGuide.pdf&p=DevEx,5066.1\n",
        "\n",
        "[5] T. (2016, January 10). Tuanavu/coursera-university-of-washington. Retrieved January 21, 2018, from https://github.com/tuanavu/coursera-university-of-washington/tree/master/machine_learning/1_machine_learning_foundations/assignment/week2\n",
        "\n",
        "[6] (n.d.). Retrieved January 21, 2018, from http://cs231n.github.io/classification/\n",
        "\n",
        "[7] (n.d.). Retrieved January 21, 2018, from http://cs231n.github.io/linear-classify/\n",
        "\n",
        "[8] Bolic, M. (2018). Principles of Data and Error Analysis in Engineering Measurements.\n",
        "\n",
        "[9] Michaël Baudin, Anne Dutfoy, Bertrand Iooss and Anne-Laure Popelin, OpenTURNS : An industrial software for uncertainty quantification in simulation, arXiv:1501.05242v2 [stat.CO] 5 Jun 2015.\n"
      ]
    },
    {
      "metadata": {
        "id": "NcgMwaA71VS6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "czMo01Vu1VS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}